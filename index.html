<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="data:,">
    <title id="pageTitle">多國語言即時逐字稿工具</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            min-height: 100vh;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            position: relative;
            padding: 20px;
        }
        #uiLangToggle {
            position: absolute;
            top: 20px;
            right: 20px;
            padding: 10px 20px;
            background-color: rgba(255, 255, 255, 0.2);
            color: white;
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 25px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 600;
            backdrop-filter: blur(10px);
            transition: all 0.3s ease;
        }
        #uiLangToggle:hover {
            background-color: rgba(255, 255, 255, 0.3);
            transform: translateY(-2px);
        }
        h1 {
            color: white;
            margin: 60px 0 30px 0;
            font-size: 28px;
            font-weight: 700;
            text-align: center;
            text-shadow: 0 2px 10px rgba(0,0,0,0.2);
        }
        .transcript-container {
            width: 90%;
            max-width: 900px;
            height: 45vh;
            margin-bottom: 20px;
            border: none;
            border-radius: 16px;
            background-color: #fff;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
            overflow-y: scroll;
            padding: 20px;
        }
        #transcript {
            white-space: pre-wrap;
            word-wrap: break-word;
            font-size: 16px;
            line-height: 1.8;
            margin: 0;
            font-family: 'Menlo', 'Monaco', 'Courier New', monospace;
            color: #333;
        }
        .interim { color: #888; font-style: italic; }
        .final_span { color: #333; }
        .placeholder { color: #999; }
        .volume-meter {
            width: 90%;
            max-width: 900px;
            height: 24px;
            background-color: rgba(255, 255, 255, 0.2);
            border-radius: 12px;
            overflow: hidden;
            margin-bottom: 20px;
            border: 2px solid rgba(255, 255, 255, 0.3);
            backdrop-filter: blur(10px);
            display: block;
        }
        .volume-level {
            height: 100%;
            width: 0%;
            background: linear-gradient(90deg, #4CAF50, #8BC34A);
            transition: width 0.1s ease-out; /* Keep fast transition for real meter */
            box-shadow: 0 0 10px rgba(76, 175, 80, 0.5);
        }
        .settings {
            display: flex;
            align-items: center;
            gap: 15px;
            margin-bottom: 20px;
            background: rgba(255, 255, 255, 0.15);
            padding: 15px 25px;
            border-radius: 12px;
            backdrop-filter: blur(10px);
            border: 2px solid rgba(255, 255, 255, 0.2);
        }
        #lang-label {
            color: white;
            font-weight: 600;
            font-size: 15px;
        }
        #languageSelector {
            padding: 10px 15px;
            font-size: 15px;
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 8px;
            background: rgba(255, 255, 255, 0.9);
            cursor: pointer;
            font-weight: 500;
            transition: all 0.3s ease;
        }
        #languageSelector:hover {
            background: white;
            border-color: rgba(255, 255, 255, 0.5);
        }
        .controls {
            display: flex;
            flex-direction: column;
            gap: 15px;
            margin-bottom: 20px;
            align-items: center;
        }
        .button-row {
            display: flex;
            gap: 15px;
        }
        button {
            padding: 14px 30px;
            font-size: 16px;
            cursor: pointer;
            border: none;
            border-radius: 12px;
            color: white;
            transition: all 0.3s ease;
            font-weight: 600;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }
        button:active {
            transform: translateY(2px);
        }
        #controlBtn {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border: 2px solid rgba(255, 255, 255, 0.3);
            position: relative;
            min-width: 160px;
        }
        #controlBtn:hover {
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
            transform: translateY(-2px);
        }
        #controlBtn.listening::after {
            content: '●';
            position: absolute;
            right: 15px;
            top: 50%;
            transform: translateY(-50%);
            color: #ff4444;
            font-size: 20px;
            animation: pulse 1.5s ease-in-out infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.3; }
        }
        #exportBtn {
            background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
            border: 2px solid rgba(255, 255, 255, 0.3);
        }
        #exportBtn:hover {
            box-shadow: 0 6px 20px rgba(17, 153, 142, 0.4);
            transform: translateY(-2px);
        }
        #exportBtn:disabled {
            background: linear-gradient(135deg, #9E9E9E 0%, #BDBDBD 100%);
            cursor: not-allowed;
            opacity: 0.6;
        }

        .warning-notice {
            background: rgba(255, 193, 7, 0.95);
            color: #000;
            padding: 12px 20px;
            border-radius: 8px;
            font-size: 14px;
            font-weight: 600;
            text-align: center;
            max-width: 600px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            border: 2px solid rgba(255, 152, 0, 0.5);
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
        }
        .warning-notice::before {
            content: '⚠️';
            font-size: 18px;
        }

        .privacy-notice {
            width: 90%;
            max-width: 900px;
            font-size: 14px;
            margin-top: auto;
            margin-bottom: 20px;
        }
        .privacy-notice details {
            border: 2px solid rgba(255, 255, 255, 0.3);
            border-radius: 12px;
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
        }
        .privacy-notice summary {
            padding: 15px 20px;
            font-weight: bold;
            cursor: pointer;
            outline: none;
            color: white;
            font-size: 15px;
        }
        .privacy-notice summary:hover {
            background: rgba(255, 255, 255, 0.1);
        }
        .privacy-notice .content {
            padding: 0 20px 20px 20px;
            line-height: 1.6;
            color: white;
        }
        .privacy-notice h3 {
            margin-top: 15px;
            margin-bottom: 8px;
            color: #FFD54F;
        }
        .privacy-notice ul {
            padding-left: 20px;
            margin: 0;
        }
        .privacy-notice ul li {
            margin-bottom: 8px;
        }
        .privacy-notice ul li.safe::before { content: '✅ '; }
        .privacy-notice ul li.unsafe::before { content: '❌ '; }
        .privacy-notice strong {
            color: #FF6B6B;
            font-weight: 700;
        }

        @media (max-width: 768px) {
            h1 { font-size: 22px; margin: 50px 20px 20px 20px; }
            .transcript-container { height: 40vh; }
            .button-row { flex-direction: column; width: 100%; }
            button { width: 100%; }
            .settings { flex-direction: column; width: 90%; }
        }
    </style>
</head>
<body>
    <button id="uiLangToggle" title="Switch the user interface language">Switch to English</button>

    <h1 id="main-title">多國語言即時逐字稿工具</h1>

    <div class="transcript-container" id="transcriptContainer">
        <pre id="transcript"><span class="placeholder" id="placeholder-text"></span></pre>
    </div>

    <div class="volume-meter">
        <div class="volume-level" id="volumeLevel"></div>
    </div>

    <div class="settings">
        <label for="languageSelector" id="lang-label">辨識語言:</label>
        <select id="languageSelector" title="選擇要進行辨識的語言">
            <option value="en-US">English (US)</option>
            <option value="en-GB">English (UK)</option>
            <option value="zh-TW">中文 (台灣)</option>
            <option value="zh-CN">中文 (中国大陆)</option>
            <option value="zh-HK">粵語 (香港)</option>
            <option value="ja-JP">日本語</option>
            <option value="ko-KR">한국어</option>
            <option value="es-ES">Español (España)</option>
            <option value="fr-FR">Français</option>
            <option value="de-DE">Deutsch</option>
        </select>
    </div>

    <div class="controls">
        <div class="button-row">
            <button id="controlBtn" title="點擊以開始語音辨識">開始辨識</button>
            <button id="exportBtn" disabled title="停止辨識後才能匯出">輸出逐字稿</button>
        </div>
        <div class="warning-notice" id="warning-text">
            本工具將把收到音檔上傳 Google 請謹慎使用
        </div>
    </div>

    <div class="privacy-notice">
        <details>
            <summary id="privacy-summary">使用須知 & 隱私聲明</summary>
            <div class="content">
                <p id="how-it-works-text"></p>
                <h3 id="suitable-scenarios-title"></h3>
                <ul id="suitable-scenarios-list"></ul>
                <h3 id="risk-scenarios-title"></h3>
                <ul id="risk-scenarios-list"></ul>
                <p id="privacy-conclusion"></p>
            </div>
        </details>
    </div>

    <script>
        // --- (DOM Elements, Translations - unchanged) ---
        const pageTitle = document.getElementById('pageTitle');
        const mainTitle = document.getElementById('main-title');
        const transcriptElement = document.getElementById('transcript');
        const transcriptContainer = document.getElementById('transcriptContainer');
        const controlBtn = document.getElementById('controlBtn');
        const exportBtn = document.getElementById('exportBtn');
        const volumeLevel = document.getElementById('volumeLevel');
        const languageSelector = document.getElementById('languageSelector');
        const langLabel = document.getElementById('lang-label');
        const uiLangToggle = document.getElementById('uiLangToggle');
        const placeholderText = document.getElementById('placeholder-text');
        const warningText = document.getElementById('warning-text');
        const privacySummary = document.getElementById('privacy-summary');
        const howItWorksText = document.getElementById('how-it-works-text');
        const suitableScenariosTitle = document.getElementById('suitable-scenarios-title');
        const suitableScenariosList = document.getElementById('suitable-scenarios-list');
        const riskScenariosTitle = document.getElementById('risk-scenarios-title');
        const riskScenariosList = document.getElementById('risk-scenarios-list');
        const privacyConclusion = document.getElementById('privacy-conclusion');
        const translations = {
             en: { pageTitle: "Multilingual Real-time Transcription Tool", mainTitle: "Multilingual Real-time Transcription Tool", langLabel: "Recognition Language:", startBtn: "Start Recognition", stopBtn: "Stop Recognition", exportBtn: "Export Transcript", toggleUiLangBtn: "切换到中文", placeholder: "Click 'Start Recognition' and your transcript will appear here...", micDeniedError: "You have denied microphone access. Please allow microphone access to use this feature.", apiNotSupportedError: "Your browser does not support the Web Speech API. Please use the latest version of Chrome.", controlBtnTooltipStart: "Click to start voice recognition", controlBtnTooltipStop: "Click to stop voice recognition", exportBtnTooltip: "Export the transcript as a .txt file", exportBtnTooltipDisabled: "Stop recognition to enable export", languageSelectorTooltip: "Select the language to be recognized", uiLangToggleTooltip: "Switch the user interface language", warningText: "This tool uploads audio to Google. Use with caution.", privacySummary: "Usage Guide & Privacy Notice", howItWorksText: "To convert speech to text, this tool uses the browser's built-in Web Speech API, which sends your voice data to Google's servers for processing. Please be aware of the following:", suitableScenariosTitle: "Suitable Scenarios:", suitableScenarios: [ "Assisting in listening to public online lectures, webinars, or courses.", "Transcribing public content like videos or podcasts.", "Personal learning and language practice." ], riskScenariosTitle: "High-Risk Scenarios (DO NOT USE):", riskScenarios: [ "Meetings involving <strong>business secrets</strong> or confidential information.", "Conversations involving <strong>personal privacy</strong> (e.g., with doctors, lawyers).", "Any content containing <strong>sensitive personal data</strong> (ID numbers, passwords, etc.)." ], privacyConclusion: "For sensitive content, it is strongly recommended to use offline tools like Whisper that process data entirely on your local machine." },
             zh: { pageTitle: "多國語言即時逐字稿工具", mainTitle: "多國語言即時逐字稿工具", langLabel: "辨識語言:", startBtn: "開始辨識", stopBtn: "停止辨識", exportBtn: "輸出逐字稿", toggleUiLangBtn: "Switch to English", placeholder: "點擊「開始辨識」後,你的逐字稿將會顯示在這裡...", micDeniedError: "您拒絕了麥克風權限。請允許麥克風存取以使用此功能。", apiNotSupportedError: "您的瀏覽器不支援 Web Speech API,請使用最新版本的 Chrome 瀏覽器。", controlBtnTooltipStart: "點擊以開始語音辨識", controlBtnTooltipStop: "點擊以停止語音辨識", exportBtnTooltip: "將逐字稿匯出為 .txt 檔案", exportBtnTooltipDisabled: "停止辨識後才能匯出", languageSelectorTooltip: "選擇要進行辨識的語言", uiLangToggleTooltip: "切換使用者介面語言", warningText: "本工具將把收到音檔上傳 Google 請謹慎使用", privacySummary: "使用須知 & 隱私聲明", howItWorksText: "本工具透過瀏覽器內建的 Web Speech API 進行語音轉文字,這會將您的聲音資料傳送到 Google の伺服器進行處理。請務必了解以下事項：", suitableScenariosTitle: "適合的使用場景：", suitableScenarios: [ "輔助聆聽公開的線上演講、課程。", "轉錄影片、Podcast 等公開內容。", "個人學習、語言練習。" ], riskScenariosTitle: "高風險場景 (絕對不要使用)：", riskScenarios: [ "任何涉及<strong>商業機密</strong>或公司內部資訊的會議。", "任何涉及<strong>個人隱私</strong>的對話 (例如與醫生、律師的對話)。", "任何包含<strong>敏感個資</strong>的內容 (如身分證號、密碼等)。" ], privacyConclusion: "針對敏感內容,強烈建議使用像 Whisper 這樣完全在您本機離線運作的工具,以確保資料安全。" }
        };

        // --- (Global Vars - unchanged) ---
        let currentUiLang = 'zh';
        let startTime, endTime;
        let transcriptSegments = [];
        let isRecognizing = false;
        let currentFinalTranscript = '';
        let currentInterimTranscript = '';
        let isManualStop = false;
        let restartTimer = null;
        let audioContext, microphoneStream, analyser, animationFrameId; // Restore meter vars

        // --- (UI Functions - unchanged) ---
        function setUiLanguage(lang) { /* ... */
            currentUiLang = lang;
            const t = translations[lang];

            pageTitle.textContent = t.pageTitle;
            mainTitle.textContent = t.mainTitle;
            langLabel.textContent = t.langLabel;
            exportBtn.textContent = t.exportBtn;
            uiLangToggle.textContent = t.toggleUiLangBtn;
            placeholderText.textContent = t.placeholder;
            uiLangToggle.title = t.uiLangToggleTooltip;
            languageSelector.title = t.languageSelectorTooltip;
            warningText.textContent = t.warningText;

            privacySummary.textContent = t.privacySummary;
            howItWorksText.textContent = t.howItWorksText;
            suitableScenariosTitle.textContent = t.suitableScenariosTitle;
            riskScenariosTitle.textContent = t.riskScenariosTitle;
            privacyConclusion.innerHTML = t.privacyConclusion;

            suitableScenariosList.innerHTML = t.suitableScenarios.map(item => `<li class="safe">${item}</li>`).join('');
            riskScenariosList.innerHTML = t.riskScenarios.map(item => `<li class="unsafe">${item}</li>`).join('');

            updateButtonStates();
        }
        function updateButtonStates() { /* ... */
             const t = translations[currentUiLang];
            controlBtn.textContent = isRecognizing ? t.stopBtn : t.startBtn;
            controlBtn.title = isRecognizing ? t.controlBtnTooltipStop : t.controlBtnTooltipStart;
            controlBtn.classList.toggle('listening', isRecognizing);
            const canExport = !!startTime;
            exportBtn.disabled = !canExport;
            exportBtn.title = canExport ? t.exportBtnTooltip : t.exportBtnTooltipDisabled;
        }
        uiLangToggle.addEventListener('click', () => { /* ... */
            const newLang = currentUiLang === 'zh' ? 'en' : 'zh';
            setUiLanguage(newLang);
        });

        // --- (Web Speech API Core Logic - Robust Continuous Mode + Real Meter) ---
        if ('webkitSpeechRecognition' in window) {
            const recognition = new webkitSpeechRecognition();
            const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);

            recognition.continuous = !isMobile;
            recognition.interimResults = true;
            recognition.maxAlternatives = 1;

            let recognitionActive = false;

            recognition.onstart = () => {
                console.log(`✅ REC: Started. Lang: ${recognition.lang}, Continuous: ${recognition.continuous}`);
                recognitionActive = true;
                isRecognizing = true;
                languageSelector.disabled = true;
                updateButtonStates();
                currentFinalTranscript = '';
                currentInterimTranscript = '';
                 // Start meter *after* recognition starts
                if (!isMobile) {
                     startAudioMeter().catch(err => console.warn("Could not start audio meter:", err));
                }
            };

            recognition.onerror = (event) => {
                console.error('Speech Recognition Error:', event.error, event);
                recognitionActive = false;
                if (event.error === 'not-allowed' || event.error === 'audio-capture') {
                    alert(event.error === 'not-allowed' ? translations[currentUiLang].micDeniedError : '麥克風擷取錯誤。');
                    isRecognizing = false;
                    isManualStop = true;
                    updateButtonStates();
                    stopAudioMeter(); // Stop meter on error
                } else {
                    console.warn(`⚠️ REC: Non-fatal error (${event.error}). Letting onend handle restart.`);
                     // Don't stop meter on non-fatal errors like 'no-speech'
                }
            };

            recognition.onend = () => {
                console.log(`⏹️ REC: Ended. (isManualStop: ${isManualStop}, isRecognizing: ${isRecognizing})`);
                recognitionActive = false;
                stopAudioMeter(); // *** Stop meter first ***

                const fullUtterance = (currentFinalTranscript + currentInterimTranscript).trim();
                if (fullUtterance) {
                    const lastSegment = transcriptSegments[transcriptSegments.length - 1];
                    const isDuplicate = lastSegment &&
                                        lastSegment.text === fullUtterance &&
                                        (Date.now() - lastSegment.timestamp.getTime()) < 1500;
                    if (!isDuplicate) {
                         console.log('...[onend] Saving full utterance:', fullUtterance);
                         transcriptSegments.push({ timestamp: new Date(), text: fullUtterance });
                    } else {
                        console.log('...[onend] Skipping duplicate save:', fullUtterance);
                    }
                    updateTranscriptDisplay();
                }
                currentFinalTranscript = '';
                currentInterimTranscript = '';
                // Volume bar is already reset by stopAudioMeter()

                if (isManualStop || !isRecognizing) {
                    console.log('...Stop condition met. Cleaning up.');
                    isRecognizing = false;
                    languageSelector.disabled = false;
                    endTime = new Date();
                    updateButtonStates();
                    clearTimeout(restartTimer);
                } else {
                    clearTimeout(restartTimer);
                    restartTimer = setTimeout(() => {
                        if (isRecognizing && !recognitionActive) {
                            try {
                                console.log('🔄 REC: Auto-restarting...');
                                recognition.start(); // onstart will restart meter
                            } catch (e) {
                                console.error('Failed to auto-restart:', e);
                                isRecognizing = false;
                                updateButtonStates();
                            }
                        } else {
                             console.log('...Restart cancelled (state changed during timeout).');
                        }
                    }, 300);
                }
            };

            // === onresult: Updates display only, using refined logic ===
            recognition.onresult = (event) => {
                let final_parts = '';
                let interim_part = ''; // Only the *last* non-final part
                console.log(`🎙️ REC: onresult (length: ${event.results.length}, index: ${event.resultIndex})`);

                // Iterate through all results for the current recognition cycle
                for (let i = 0; i < event.results.length; ++i) {
                    const transcript = event.results[i][0].transcript;
                    const isFinal = event.results[i].isFinal;

                    if (isFinal) {
                        final_parts += transcript + ' ';
                    } else {
                        interim_part = transcript; // Overwrite with the latest interim guess
                    }
                }

                currentFinalTranscript = final_parts.trim();
                currentInterimTranscript = interim_part; // Store the latest interim guess

                updateTranscriptDisplay();
                // Real volume meter updates independently
            };


            function updateTranscriptDisplay() {
                const historyContent = transcriptSegments.map(segment => `<span class="final_span">${formatTime(segment.timestamp)} ${segment.text}</span>`).join('\n');
                const currentFinalSpan = currentFinalTranscript ? `<span class="final_span">${currentFinalTranscript}</span>` : '';
                const interimPrefix = currentFinalTranscript && currentInterimTranscript ? ' ' : '';
                const currentInterimSpan = currentInterimTranscript ? `<span class="interim">${interimPrefix}${currentInterimTranscript}</span>` : '';

                const hasContent = transcriptSegments.length > 1 || currentFinalTranscript || currentInterimTranscript;
                placeholderText.style.display = hasContent ? 'none' : 'inline';

                transcriptElement.innerHTML = `${historyContent}\n${currentFinalSpan}${currentInterimSpan}`;
                transcriptContainer.scrollTop = transcriptContainer.scrollHeight;
            }


            // === controlBtn: Stops meter explicitly ===
             controlBtn.addEventListener('click', () => {
                if (isRecognizing) {
                    console.log('■ UI: Stop button clicked.');
                    isManualStop = true;
                    isRecognizing = false;
                    recognitionActive = false;
                    clearTimeout(restartTimer);
                    stopAudioMeter(); // Stop meter NOW
                    try {
                        recognition.stop();
                    } catch (e) {
                        console.warn('Error stopping recognition:', e);
                        languageSelector.disabled = false;
                        endTime = new Date();
                        updateButtonStates();
                    }
                } else {
                    isManualStop = false;
                    isRecognizing = true;
                    recognition.lang = languageSelector.value;
                    console.log(`▶️ UI: Start button clicked. Lang: ${recognition.lang}`);
                    startTime = new Date();
                    endTime = null;
                    transcriptSegments = [];
                    currentFinalTranscript = '';
                    currentInterimTranscript = '';
                    transcriptSegments.push({ timestamp: startTime, text: '--- Recording Start / 錄音開始 ---' });
                    updateTranscriptDisplay();
                    updateButtonStates();
                    if (!recognitionActive) {
                        try {
                            recognition.start(); // onstart will handle meter start
                        } catch (e) {
                            console.error('Failed to start recognition:', e);
                            if (e.message.includes('already started')) {
                                console.warn('...forcing stop and restart.');
                                try { recognition.stop(); } catch(stopErr) {}
                                clearTimeout(restartTimer);
                                stopAudioMeter();
                                setTimeout(() => {
                                    try {
                                        isManualStop = false;
                                        isRecognizing = true;
                                        recognition.start();
                                    } catch (e2) {
                                        console.error('Still failed:', e2);
                                        alert('無法啟動語音辨識,請重新整理頁面再試。\nFailed to start recognition, please refresh and try again.');
                                    }
                                }, 500);
                            } else {
                                alert('無法啟動語音辨識,請重新整理頁面再試。\nFailed to start recognition, please refresh and try again.');
                            }
                        }
                    }
                }
            });

            // === Export logic (unchanged) ===
            exportBtn.addEventListener('click', () => {
                if (!startTime) return;
                const effectiveEndTime = endTime || new Date();

                const allSegmentsForExport = [...transcriptSegments];
                const lingeringUtterance = (currentFinalTranscript + currentInterimTranscript).trim();
                 if (endTime && lingeringUtterance) { // Only add if manually stopped *during* speech
                     const lastSegment = allSegmentsForExport[allSegmentsForExport.length - 1];
                     const isDuplicate = lastSegment &&
                                        lastSegment.text === lingeringUtterance &&
                                        (effectiveEndTime.getTime() - lastSegment.timestamp.getTime()) < 1000;
                    if (!isDuplicate) {
                        console.log("...Adding lingering utterance to export:", lingeringUtterance);
                        allSegmentsForExport.push({ timestamp: effectiveEndTime, text: lingeringUtterance });
                    }
                }

                const header = `--- 開始錄製時間 (Start Time) ---\r\n${formatFullDateTime(startTime)}\r\n\r\n--- 逐字稿內容 (Transcript) ---\r\n`;
                const transcriptContent = allSegmentsForExport.map(segment => `${formatTime(segment.timestamp)} ${segment.text}`).join('\r\n');
                const footer = `\r\n\r\n--- 匯出結束時間 (Export Time) ---\r\n${formatFullDateTime(effectiveEndTime)}\r\n`;
                const textToSave = header + transcriptContent + footer;

                const fileName = createFileName(startTime, effectiveEndTime);
                const blob = new Blob([textToSave], { type: 'text/plain' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = fileName;
                a.click();
                URL.revokeObjectURL(url);
            });

        } else {
            alert(translations.en.apiNotSupportedError);
        }

        // --- (Helper Functions) ---

        function formatTime(date) {
            const h = formatTwoDigits(date.getHours());
            const m = formatTwoDigits(date.getMinutes());
            const s = formatTwoDigits(date.getSeconds());
            return `[${h}:${m}:${s}]`;
        }

        function formatFullDateTime(date) {
            const Y = date.getFullYear();
            const M = formatTwoDigits(date.getMonth() + 1);
            const D = formatTwoDigits(date.getDate());
            const h = formatTwoDigits(date.getHours());
            const m = formatTwoDigits(date.getMinutes());
            const s = formatTwoDigits(date.getSeconds());
            return `${Y}-${M}-${D} ${h}:${m}:${s}`;
        }

        // === Real Volume Meter Functions (Restored) ===
        async function startAudioMeter() {
            console.log("🎤 Attempting to start audio meter...");
             if (audioContext || !isRecognizing) {
                 console.log("...Audio meter already running or recognition stopped.");
                 return;
             }
            if (!navigator.mediaDevices?.getUserMedia) {
                console.warn("getUserMedia not supported, cannot start audio meter.");
                return Promise.reject('getUserMedia not supported');
            }
            try {
                microphoneStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                // Use existing audioContext if available and running, else create new
                if (!audioContext || audioContext.state === 'closed') {
                     audioContext = new (window.AudioContext || window.webkitAudioContext)();
                     console.log("...New AudioContext created.");
                } else {
                     console.log("...Reusing existing AudioContext.");
                }
                analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(microphoneStream);
                source.connect(analyser);
                drawVolume(); // Start the drawing loop
                console.log("🔊 Audio meter started successfully.");
            } catch (err) {
                 console.error("Error starting audio meter:", err);
                 stopAudioMeter(); // Clean up if start failed
                 // Don't re-throw, just warn. Meter is optional.
                 // throw err;
            }
        }

        function stopAudioMeter() {
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId);
                animationFrameId = null;
                 console.log("⏹️ Audio meter drawing stopped.");
            }
            if (microphoneStream) {
                microphoneStream.getTracks().forEach(track => track.stop());
                microphoneStream = null;
                console.log("🎤 Microphone stream stopped.");
            }
            // Only close context if it exists and is running/suspended
            if (audioContext && (audioContext.state === 'running' || audioContext.state === 'suspended')) {
                 // Check state before closing
                audioContext.close().then(() => {
                    console.log("🎧 Audio context closed.");
                    audioContext = null;
                    analyser = null;
                 }).catch(err => {
                    console.error("Error closing audio context:", err);
                    // Still nullify even if closing failed
                    audioContext = null;
                    analyser = null;
                 });
            } else if (audioContext && audioContext.state === 'closed') {
                 console.log("...Audio context already closed.");
                 audioContext = null; // Ensure nullified
                 analyser = null;
            } else {
                 audioContext = null;
                 analyser = null;
            }
            volumeLevel.style.width = '0%';
        }


        function drawVolume() {
            if (!analyser || !isRecognizing) {
                 if (animationFrameId) {
                    cancelAnimationFrame(animationFrameId);
                    animationFrameId = null;
                 }
                 volumeLevel.style.width = '0%';
                return;
            }
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteTimeDomainData(dataArray);
            let sumSquares = 0.0;
            for (const amplitude of dataArray) {
                const a = (amplitude / 128.0) - 1.0;
                sumSquares += a * a;
            }
            const rms = Math.sqrt(sumSquares / dataArray.length);
            const volume = Math.min(100, rms * 100 * 10);
            volumeLevel.style.width = volume + '%';
            animationFrameId = requestAnimationFrame(drawVolume);
        }

        // === Removed simulateVolume ===

        function formatTwoDigits(n) {
            return n < 10 ? '0' + n : n;
        }

        function createFileName(start, end) {
            const date = `${start.getFullYear()}-${formatTwoDigits(start.getMonth() + 1)}-${formatTwoDigits(start.getDate())}`;
            const startTimeStr = `${formatTwoDigits(start.getHours())}-${formatTwoDigits(start.getMinutes())}-${formatTwoDigits(start.getSeconds())}`;
            const endTimeStr = `${formatTwoDigits(end.getHours())}-${formatTwoDigits(end.getMinutes())}-${formatTwoDigits(end.getSeconds())}`;
            return `${date}_${startTimeStr}_to_${endTimeStr}.txt`;
        }

        document.addEventListener('DOMContentLoaded', () => {
            const browserLang = navigator.language || navigator.userLanguage;
            setUiLanguage(browserLang.startsWith('zh') ? 'zh' : 'en');
            updateTranscriptDisplay();
        });
    </script>
</body>
</html>
